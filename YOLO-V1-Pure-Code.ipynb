{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZoTZQuIuCJPFQbZ8jhms0zGBumqYJKQY","timestamp":1753983539406},{"file_id":"1RKVd1Jqqe8zXJSuNbCtUymzNnXIY2Qrf","timestamp":1753756610526},{"file_id":"1vPIBg7AylLP_POJs-BiHjkRfR1nxxX7h","timestamp":1753755997993},{"file_id":"1FGaM9muPNmyT2HWVnbGFKeuGbiAXosR8","timestamp":1753755883592},{"file_id":"1AWu351DPgNwTxmMko1mUk_jRQEqCcCyd","timestamp":1753664679759},{"file_id":"15f5N5EzcIsq4rNevmR6MgXADm1rqVP2P","timestamp":1753635184216}],"gpuType":"T4","authorship_tag":"ABX9TyO17/lL09BrnoVdAxryiYcN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**YOLO v1 from Scratch**"],"metadata":{"id":"pvu0TlOum62b"}},{"cell_type":"markdown","source":["####Getting the Data\n","Downloading Pascal VOC Dataset"],"metadata":{"id":"qgz5Y954jrUe"}},{"cell_type":"code","source":["!pip install opendatasets --q\n","import opendatasets as od\n","od.download('https://www.kaggle.com/datasets/aladdinpersson/pascalvoc-yolo', data_dir='YOLOv1_Dataset')"],"metadata":{"id":"azv3z0HJkxx7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Libraries"],"metadata":{"id":"3vC8d7fikX9H"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"SQ3gz2GCaKKx","executionInfo":{"status":"ok","timestamp":1753983278342,"user_tz":360,"elapsed":15961,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","import torchvision.transforms as transforms\n","\n","import torch.nn.functional as F\n","import torchvision.transforms.functional as FT\n","\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","import os\n","from tqdm.auto import tqdm\n","\n","from collections import Counter\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","from PIL import Image\n","\n","import matplotlib.patches as patches\n","\n","import random"]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"yiTBqFdbkQ-0","executionInfo":{"status":"ok","timestamp":1753983278344,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(2)"],"metadata":{"id":"LTcmMHS0nH2M","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Utils"],"metadata":{"id":"PvggeRjqZmo8"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"vAN6UsswqxKJ"}},{"cell_type":"code","source":["# @title Calculationg IOU\n","def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n","\n","    if box_format == \"midpoint\":\n","        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n","        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n","        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n","        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n","        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n","        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n","        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n","        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n","\n","    if box_format == \"corners\":\n","        box1_x1 = boxes_preds[..., 0:1]\n","        box1_y1 = boxes_preds[..., 1:2]\n","        box1_x2 = boxes_preds[..., 2:3]\n","        box1_y2 = boxes_preds[..., 3:4]\n","        box2_x1 = boxes_labels[..., 0:1]\n","        box2_y1 = boxes_labels[..., 1:2]\n","        box2_x2 = boxes_labels[..., 2:3]\n","        box2_y2 = boxes_labels[..., 3:4]\n","\n","\n","    x1 = torch.max(box1_x1, box2_x1)\n","    y1 = torch.max(box1_y1, box2_y1)\n","    x2 = torch.min(box1_x2, box2_x2)\n","    y2 = torch.min(box1_y2, box2_y2)\n","\n","    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n","\n","    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n","    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n","\n","    return intersection / (box1_area + box2_area - intersection + 1e-6)"],"metadata":{"id":"2nd7i8EsZpz6","executionInfo":{"status":"ok","timestamp":1753983278354,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"RNUQQ1iCqy4g"}},{"cell_type":"code","source":["# @title Non-Max Superssion\n","def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"midpoint\"):\n","\n","    assert type(bboxes) == list\n","\n","    bboxes = [box for box in bboxes if torch.sigmoid(torch.tensor(box[1])).item() > threshold]\n","    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n","\n","    bboxes_after_nms = []\n","\n","    while bboxes:\n","        chosen_box = bboxes.pop(0)\n","\n","        bboxes = [\n","            box\n","            for box in bboxes\n","            if box[0] != chosen_box[0]\n","            or intersection_over_union(\n","                torch.tensor(chosen_box[2:]),\n","                torch.tensor(box[2:]),\n","                box_format=box_format,\n","            )\n","            < iou_threshold\n","        ]\n","\n","        bboxes_after_nms.append(chosen_box)\n","\n","    return bboxes_after_nms"],"metadata":{"id":"UjNZ40g0Ioe_","executionInfo":{"status":"ok","timestamp":1753983278356,"user_tz":360,"elapsed":0,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"rZrJ7yAkqz9E"}},{"cell_type":"code","source":["# @title Calculating mAP\n","def mean_average_precision(\n","    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20\n","):\n","\n","    average_precisions = []\n","\n","    epsilon = 1e-6\n","\n","    for c in range(num_classes):\n","        detections = []\n","        ground_truths = []\n","\n","        for detection in pred_boxes:\n","            if detection[1] == c:\n","                detections.append(detection)\n","\n","        for true_box in true_boxes:\n","            if true_box[1] == c:\n","                ground_truths.append(true_box)\n","\n","        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n","\n","        for key, val in amount_bboxes.items():\n","          amount_bboxes[key] = torch.zeros(val)\n","\n","        detections.sort(key=lambda x: x[2], reverse=True)\n","        TP = torch.zeros((len(detections)))\n","        FP = torch.zeros((len(detections)))\n","        total_true_bboxes = len(ground_truths)\n","\n","        if total_true_bboxes == 0:\n","            continue\n","\n","        for detection_idx, detection in enumerate(detections):\n","            ground_truth_img = [\n","                bbox for bbox in ground_truths if bbox[0] == detection[0]\n","            ]\n","\n","            num_gts = len(ground_truth_img)\n","            best_iou = 0\n","\n","            for idx, gt in enumerate(ground_truth_img):\n","                iou = intersection_over_union(\n","                    torch.tensor(detection[3:]),\n","                    torch.tensor(gt[3:]),\n","                    box_format=box_format,\n","                )\n","\n","                if iou > best_iou:\n","                    best_iou = iou\n","                    best_gt_idx = idx\n","\n","            if best_iou > iou_threshold:\n","                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n","                    TP[detection_idx] = 1\n","                    amount_bboxes[detection[0]][best_gt_idx] = 1\n","                else:\n","                    FP[detection_idx] = 1\n","\n","            else:\n","                FP[detection_idx] = 1\n","\n","        TP_cumsum = torch.cumsum(TP, dim=0)\n","        FP_cumsum = torch.cumsum(FP, dim=0)\n","        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n","        precisions = torch.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n","        precisions = torch.cat((torch.tensor([1]), precisions))\n","        recalls = torch.cat((torch.tensor([0]), recalls))\n","        average_precisions.append(torch.trapz(precisions, recalls))\n","\n","    return sum(average_precisions) / len(average_precisions)"],"metadata":{"id":"5WeVisMQI3V-","executionInfo":{"status":"ok","timestamp":1753983278357,"user_tz":360,"elapsed":0,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"0120BO15q1jG"}},{"cell_type":"code","source":["# @title Bounding Boxes cordinates relative to Grid Cell --> Bounding Boxes cordinates relative to Image\n","def convert_cellboxes(predictions, S=7):\n","\n","    predictions = predictions.to(\"cpu\")\n","    batch_size = predictions.shape[0]\n","    predictions = predictions.reshape(batch_size, 7, 7, 30)\n","    bboxes1 = predictions[..., 21:25]\n","    bboxes2 = predictions[..., 26:30]\n","    scores = torch.cat(\n","        (predictions[..., 20].unsqueeze(0), predictions[..., 25].unsqueeze(0)), dim=0\n","    )\n","    best_box = scores.argmax(0).unsqueeze(-1)\n","    best_boxes = bboxes1 * (1 - best_box) + best_box * bboxes2\n","    cell_indices = torch.arange(7).repeat(batch_size, 7, 1).unsqueeze(-1)\n","    x = 1 / S * (best_boxes[..., :1] + cell_indices)\n","    y = 1 / S * (best_boxes[..., 1:2] + cell_indices.permute(0, 2, 1, 3))\n","    w_y = 1 / S * best_boxes[..., 2:4]\n","    converted_bboxes = torch.cat((x, y, w_y), dim=-1)\n","    predicted_class = predictions[..., :20].argmax(-1).unsqueeze(-1)\n","    best_confidence = torch.max(predictions[..., 20], predictions[..., 25]).unsqueeze(\n","        -1\n","    )\n","    converted_preds = torch.cat(\n","        (predicted_class, best_confidence, converted_bboxes), dim=-1\n","    )\n","\n","    return converted_preds"],"metadata":{"id":"l3yv5Kd1JhI6","executionInfo":{"status":"ok","timestamp":1753983278465,"user_tz":360,"elapsed":107,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# @title Convert Grid Cell Predictions to Per-Image Bounding Box Lists\n","def cellboxes_to_boxes(out, S=7):\n","    converted_pred = convert_cellboxes(out).reshape(out.shape[0], S * S, -1)\n","    converted_pred[..., 0] = converted_pred[..., 0].long()\n","    all_bboxes = []\n","\n","    for ex_idx in range(out.shape[0]):\n","        bboxes = []\n","\n","        for bbox_idx in range(S * S):\n","            bboxes.append([x.item() for x in converted_pred[ex_idx, bbox_idx, :]])\n","        all_bboxes.append(bboxes)\n","\n","    return all_bboxes"],"metadata":{"id":"iQrqd5HT4Tia","executionInfo":{"status":"ok","timestamp":1753983278467,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# @title Extract and Postprocess Bounding Boxes from a DataLoader Using\n","def get_bboxes(\n","    loader,\n","    model,\n","    iou_threshold,\n","    threshold,\n","    pred_format=\"cells\",\n","    box_format=\"midpoint\",\n","    device=\"cuda\",\n","):\n","    all_pred_boxes = []\n","    all_true_boxes = []\n","\n","    model.eval()\n","    train_idx = 0\n","\n","    for batch_idx, (x, labels) in enumerate(loader):\n","        x = x.to(device)\n","        labels = labels.to(device)\n","\n","        with torch.no_grad():\n","            predictions = model(x)\n","\n","        batch_size = x.shape[0]\n","        true_bboxes = cellboxes_to_boxes(labels)\n","        bboxes = cellboxes_to_boxes(predictions)\n","\n","        for idx in range(batch_size):\n","            nms_boxes = non_max_suppression(\n","                bboxes[idx],\n","                iou_threshold=iou_threshold,\n","                threshold=threshold,\n","                box_format=box_format,\n","            )\n","\n","            for nms_box in nms_boxes:\n","                all_pred_boxes.append([train_idx] + nms_box)\n","\n","            for box in true_bboxes[idx]:\n","                if box[1] > threshold:\n","                    all_true_boxes.append([train_idx] + box)\n","\n","            train_idx += 1\n","\n","    model.train()\n","    return all_pred_boxes, all_true_boxes"],"metadata":{"id":"VQEkGHZj4c_7","executionInfo":{"status":"ok","timestamp":1753983278468,"user_tz":360,"elapsed":0,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# @title Plot Predicted Bounding Boxes on the Image\n","def plot_image(image, boxes, class_names=None):\n","\n","    im = np.array(image)\n","    height, width, _ = im.shape\n","\n","    fig, ax = plt.subplots(1)\n","    ax.imshow(im)\n","\n","    color_map = plt.get_cmap('tab20')\n","\n","    for box in boxes:\n","        bbox_class_id = int(box[0])\n","        confidence_score = torch.sigmoid(torch.tensor(box[1])).item()\n","\n","        box = box[2:]\n","        assert len(box) == 4, \"Got more values than in x, y, w, h, in a box!\"\n","\n","        x_center, y_center, w, h = box\n","\n","        x1 = x_center - w / 2\n","        y1 = y_center - h / 2\n","        x2 = x_center + w / 2\n","        y2 = y_center + h / 2\n","\n","        x1 = max(0.0, x1)\n","        y1 = max(0.0, y1)\n","        x2 = min(1.0, x2)\n","        y2 = min(1.0, y2)\n","\n","        w = x2 - x1\n","        h = y2 - y1\n","\n","        color = color_map(bbox_class_id % 20)\n","\n","        rect = patches.Rectangle(\n","            (x1 * width, y1 * height),\n","            w * width,\n","            h * height,\n","            linewidth=2,\n","            edgecolor=color,\n","            facecolor=\"none\",\n","        )\n","        ax.add_patch(rect)\n","\n","        bbox_text_label = f'{class_names[bbox_class_id] if class_names else bbox_class_id}: {confidence_score:.2f}'\n","\n","        ax.text(\n","            x1 * width, y1 * height,\n","            bbox_text_label,\n","            fontsize=6,\n","            color='white',\n","            verticalalignment='top',\n","            bbox={\n","                'facecolor': color,\n","                'alpha': 0.6,\n","                'pad': 1,\n","                'edgecolor': 'none'\n","            }\n","        )\n","\n","    plt.axis('off')\n","\n","    plt.show()"],"metadata":{"id":"A6nUKXiPJb4D","executionInfo":{"status":"ok","timestamp":1753983278469,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"YgLeDIaArcvH"}},{"cell_type":"code","source":["# @title Saving and Loading the Checkpoints\n","def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])"],"metadata":{"id":"-mjmCDm84oDS","executionInfo":{"status":"ok","timestamp":1753983278648,"user_tz":360,"elapsed":178,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"y0Ku8EuSst8C"}},{"cell_type":"markdown","source":["#Architecture"],"metadata":{"id":"hAKql3OMkCAT"}},{"cell_type":"code","source":["architecture_config = [\n","    (7, 64, 2, 3),\n","    'M',\n","\n","    (3, 192, 1, 1),\n","    'M',\n","\n","    (1, 128, 1, 0),\n","    (3, 256, 1, 1),\n","    (1, 256, 1, 0),\n","    (3, 512, 1, 1),\n","    'M',\n","\n","    [(1, 256, 1, 0), (3, 512, 1, 1), 4],\n","    (1, 512, 1, 0),\n","    (3, 1024, 1, 1),\n","    'M',\n","\n","    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],\n","    (3, 1024, 1, 1),\n","    (3, 1024, 2, 1),\n","\n","    (3, 1024, 1, 1),\n","    (3, 1024, 1, 1),\n","]"],"metadata":{"id":"yNf4amgEj-m3","executionInfo":{"status":"ok","timestamp":1753983278649,"user_tz":360,"elapsed":178,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class CNN_block(nn.Module):\n","  def __init__(self, in_channels, out_channels, **kwargs):\n","    super().__init__()\n","\n","    self.Conv = nn.Conv2d(in_channels=in_channels,\n","                          out_channels=out_channels,\n","                          bias=False,\n","                          **kwargs)\n","\n","    self.BN = nn.BatchNorm2d(out_channels)\n","\n","\n","  def forward(self, X):\n","    out = self.Conv(X)\n","    out = self.BN(out)\n","    out = F.gelu(out)\n","\n","    return out"],"metadata":{"id":"zKabReNbm0tL","executionInfo":{"status":"ok","timestamp":1753983278931,"user_tz":360,"elapsed":281,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class YOLOv1(nn.Module):\n","  def __init__(self, in_channels=3, arch_config=architecture_config, **kwargs):\n","   super().__init__()\n","\n","   self.architecture_config = arch_config\n","   self.in_channels = in_channels\n","\n","   self.darknet = self._create_conv_layers(self.architecture_config)\n","\n","   self.fc = self._create_fcs(**kwargs)\n","\n","\n","  def _create_conv_layers(self, architecture_config):\n","    layers = []\n","\n","    in_channels = self.in_channels\n","\n","    for layer in architecture_config:\n","      if type(layer) == tuple:\n","        layers += [CNN_block(in_channels=in_channels,\n","                             out_channels=layer[1],\n","                             kernel_size=layer[0],\n","                             stride=layer[2],\n","                             padding=layer[3])]\n","\n","        in_channels = layer[1]\n","\n","      elif type(layer) == str:\n","        layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=2)]\n","\n","      else:\n","        conv1 = layer[0]\n","        conv2 = layer[1]\n","        num_repeats = layer[2]\n","\n","        for _ in range(num_repeats):\n","          layers += [CNN_block(in_channels=in_channels,\n","                               out_channels=conv1[1],\n","                               kernel_size=conv1[0],\n","                               stride=conv1[2],\n","                               padding=conv1[3])]\n","\n","          layers += [CNN_block(in_channels=conv1[1],\n","                               out_channels=conv2[1],\n","                               kernel_size=conv2[0],\n","                               stride=conv2[2],\n","                               padding=conv2[3])]\n","\n","          in_channels = conv2[1]\n","\n","    return nn.Sequential(*layers)\n","\n","  #IF YOU WANT FASTER RESULTS YOU CAN CHANGE THESE HYPERPARAMETERS FOR LOWER ONES\n","  def _create_fcs(self, split_size, num_boxes, num_classes):\n","    fcs = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(1024 * split_size * split_size, 4096),\n","        nn.GELU(), #ORIGINAL PAPER USED LEAKY RELU (YOU CAN CHANGE IT)\n","        nn.Dropout(0.5),\n","        nn.Linear(4096, split_size * split_size * (num_classes + 5 * num_boxes))\n","    )\n","\n","    return fcs\n","\n","\n","  def forward(self, X):\n","    out = self.darknet(X)\n","    out = torch.flatten(out, start_dim=1)\n","    out = self.fc(out)\n","\n","    return out"],"metadata":{"id":"7K_VwB3z7tHV","executionInfo":{"status":"ok","timestamp":1753983278932,"user_tz":360,"elapsed":281,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["#Loss"],"metadata":{"id":"1hyS9qhxX20N"}},{"cell_type":"code","source":["class YOLO_Loss(nn.Module):\n","  def __init__(self, split_size=7, num_bboxes=2, num_classes=20):\n","    super().__init__()\n","\n","    self.MSE = nn.MSELoss(reduction='sum')\n","\n","    self.S = split_size\n","    self.B = num_bboxes\n","    self.C = num_classes\n","\n","    self.lambda_noobj = 0.5\n","    self.lambda_coord = 5\n","\n","  def forward(self, preds, target):\n","    preds = preds.reshape(-1, self.S, self.S, self.C + 5 * self.B)\n","\n","    iou_b1 = intersection_over_union(preds[..., self.C+1 : self.C+1+4], #21 : 25\n","                                     target[..., self.C+1 : self.C+1+4])#21 : 25\n","\n","    iou_b2 = intersection_over_union(preds[..., self.C+1+5 : self.C+1+4+5], #26 : 30\n","                                     target[..., self.C+1 : self.C+1+4])#21 : 25\n","\n","    ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n","\n","    best_box = torch.argmax(ious, dim=0)\n","\n","\n","    exists_box = target[..., 20].unsqueeze(3)\n","\n","\n","    #=========================#\n","    # LOSS FOR BOX CORDINATES #\n","    #=========================#\n","\n","    box_preds = exists_box * (\n","        (\n","            best_box * preds[..., 26 : 30] +\n","            (1 - best_box) * preds[..., 21 : 25]\n","        )\n","      )\n","\n","    box_targets = exists_box * target[..., 21 : 25]\n","\n","\n","    box_preds[..., 2 : 4] = torch.sign(box_preds[..., 2:4]) * torch.sqrt(\n","        torch.abs(box_preds[..., 2 : 4] + 1e-8)\n","    )\n","\n","    box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2 : 4])\n","\n","    box_loss = self.MSE(\n","        torch.flatten(box_preds, end_dim=-2),\n","        torch.flatten(box_targets, end_dim=-2))\n","\n","\n","    #======================#\n","    # LOSS FOR OBJECT LOSS #\n","    #======================#\n","\n","    pred_box = (\n","        best_box * preds[..., 25:26] +\n","        + (1 - best_box) * preds[..., 20:21]\n","    )\n","\n","    object_loss = self.MSE(\n","        torch.flatten(exists_box * pred_box, start_dim=1),\n","        torch.flatten(exists_box * target[..., 20:21], start_dim=1))\n","\n","\n","    #=========================#\n","    # LOSS FOR NO OBJECT LOSS #\n","    #=========================#\n","\n","    no_object_loss = self.MSE(\n","        torch.flatten((1 - exists_box) * preds[..., 20:21], start_dim=1),\n","        torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1))\n","\n","    no_object_loss += self.MSE(\n","        torch.flatten((1 - exists_box) * preds[..., 25:26], start_dim=1),\n","        torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1))\n","\n","\n","    #=====================#\n","    # LOSS FOR CLASS LOSS #\n","    #=====================#\n","\n","    class_loss = self.MSE(\n","        torch.flatten(exists_box * preds[..., :self.C], end_dim=-2),\n","        torch.flatten(exists_box * target[..., :self.C], end_dim=-2)\n","    )\n","\n","\n","    #=====================#\n","    #        LOSS         #\n","    #=====================#\n","\n","    loss = (\n","        self.lambda_coord * box_loss\n","        + object_loss\n","        + self.lambda_noobj * no_object_loss\n","        + class_loss\n","    )\n","\n","    return loss"],"metadata":{"id":"EDI1JjpbQNin","executionInfo":{"status":"ok","timestamp":1753983278933,"user_tz":360,"elapsed":119,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["#Data Configuration"],"metadata":{"id":"BjJ4WnYenGYp"}},{"cell_type":"code","source":["class VOC_Dataset(Dataset):\n","  def __init__(self, csv_file, img_dir, label_dir, S=7, B=2, C=20, transform=None):\n","\n","    self.annotations = pd.read_csv(csv_file)\n","    self.img_dir = img_dir\n","    self.label_dir = label_dir\n","    self.transform = transform\n","\n","    self.S = S\n","    self.B = B\n","    self.C = C\n","\n","  def __len__(self):\n","    return len(self.annotations)\n","\n","  def __getitem__(self, idx):\n","    label_path = os.path.join(self.label_dir, self.annotations.iloc[idx, 1])\n","\n","    boxes = []\n","\n","    with open(label_path) as f:\n","      for label in f.readlines():\n","\n","        class_label, x, y, width, height = [\n","            float(x) if float(x) != int(float(x)) else int(x)\n","            for x in label.replace('\\n', '').split()\n","        ]\n","\n","        boxes.append([class_label, x, y, width, height])\n","\n","    img_path = os.path.join(self.img_dir, self.annotations.iloc[idx, 0])\n","    image = Image.open(img_path)\n","\n","    boxes = torch.tensor(boxes)\n","\n","    if self.transform:\n","      image, boxes = self.transform(image, boxes)\n","\n","    label_matrix = torch.zeros((self.S, self.S, self.C + (5 * self.B)))\n","\n","    for box in boxes:\n","      class_label, x, y, width, height = box.tolist()\n","      class_label = int(class_label)\n","\n","      i, j = int(self.S * y), int(self.S * x)\n","\n","      x_cell, y_cell = self.S * x - j, self.S * y - i\n","\n","      width_cell, height_cell = (\n","          width * self.S,\n","          height * self.S\n","      )\n","\n","      if label_matrix[i, j, 20] == 0:\n","        label_matrix[i, j, 20] = 1\n","\n","        box_cordinates = torch.tensor(\n","            [x_cell, y_cell, width_cell, height_cell]\n","        )\n","\n","        label_matrix[i, j, 21:25] = box_cordinates\n","        label_matrix[i, j, class_label] = 1\n","\n","    return image, label_matrix"],"metadata":{"id":"0c-yp6v1ut9x","executionInfo":{"status":"ok","timestamp":1753983278941,"user_tz":360,"elapsed":24,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["##Data Augmentation"],"metadata":{"id":"ucRmZ5Cz7_z_"}},{"cell_type":"markdown","source":["In the original paper they used way more / different data augmentation, but it would take weeks if we use the one the autors have used. If you want to read all of the augmentations please read the last paragraph of '2.2 Training' in the paper"],"metadata":{"id":"0UYVVW09nLvv"}},{"cell_type":"code","source":["class Compose(object):\n","  def __init__(self, transforms):\n","    self.transforms = transforms\n","\n","  def __call__(self, img, bboxes):\n","    boxes = bboxes\n","    for transform in self.transforms:\n","      try:\n","        img, boxes = transform(img, bboxes)\n","\n","      except TypeError:\n","        img = transform(img)\n","\n","    return img, boxes"],"metadata":{"id":"nbUw-O0E8KxQ","executionInfo":{"status":"ok","timestamp":1753983278942,"user_tz":360,"elapsed":13,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train_transform = Compose([\n","    transforms.Resize((448, 448)),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","test_transform = Compose([\n","    transforms.Resize((448, 448)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])"],"metadata":{"id":"4zKkDB7l8L66","executionInfo":{"status":"ok","timestamp":1753983279033,"user_tz":360,"elapsed":103,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["##Creating Train and Test Datasets"],"metadata":{"id":"6VxnfaL6mvLR"}},{"cell_type":"code","source":["IMG_DIR = '/content/YOLOv1_Dataset/pascalvoc-yolo/images'\n","LABEL_DIR = '/content/YOLOv1_Dataset/pascalvoc-yolo/labels'"],"metadata":{"id":"PZjEv3hKm_n-","executionInfo":{"status":"ok","timestamp":1753983279317,"user_tz":360,"elapsed":283,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["train_dataset = VOC_Dataset(\n","    '/content/YOLOv1_Dataset/pascalvoc-yolo/train.csv',\n","    IMG_DIR,\n","    LABEL_DIR,\n","    transform=train_transform\n","    )\n","\n","test_dataset = VOC_Dataset(\n","    '/content/YOLOv1_Dataset/pascalvoc-yolo/test.csv',\n","    IMG_DIR,\n","    LABEL_DIR,\n","    transform=test_transform\n","    )"],"metadata":{"id":"RkgyU9pRlv71","executionInfo":{"status":"ok","timestamp":1753983279319,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["##Creating Train and Test Dataloaders"],"metadata":{"id":"rSyUlgcepnTU"}},{"cell_type":"code","source":["BATCH_SIZE = 64\n","NUM_WORKERS = 2\n","PIN_MEMORY = True"],"metadata":{"id":"aUGfN5f7qOae","executionInfo":{"status":"ok","timestamp":1753983279320,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["train_dl = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=BATCH_SIZE,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=PIN_MEMORY,\n","    shuffle=False,\n","    drop_last=True\n",")\n","\n","test_dl = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=BATCH_SIZE,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=PIN_MEMORY,\n","    shuffle=False,\n","    drop_last=False\n",")"],"metadata":{"id":"JQysSbUZpr7Q","executionInfo":{"status":"ok","timestamp":1753983279321,"user_tz":360,"elapsed":0,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["#Training"],"metadata":{"id":"vb-SnyMl3VNY"}},{"cell_type":"code","source":["# @title ####Training Hyperparameters\n","\n","seed = 24\n","\n","#FOR FAST RESULTS:\n","LR = 2e-5\n","WEIGHT_DECAY = 1e-4\n","EPOCHS = 12\n","\n","#ORIGINAL PAPER USED:\n","\"\"\"\n","NUM_EPOCHS = 135\n","BATCH_SIZE = 64\n","INITIAL_LR = 0.001\n","LR_DECAY_EPOCH = 75  # After this epoch, LR is decreased\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 0.0005\n","\n","optimizer = optim.SGD(\n","    model.parameters(),\n","    lr=INITIAL_LR,\n","    momentum=MOMENTUM,\n","    weight_decay=WEIGHT_DECAY\n",")\n","\n","lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","    optimizer,\n","    milestones=[LR_DECAY_EPOCH],\n","    gamma=0.1  # LR *= 0.1 after milestone\n","\"\"\"\n","SHOW_TRAIN_BATCH_PICS = 25\n","SHOW_TEST_BATCH_PICS = 5\n","SAVE_MODEL = False\n","LOAD_MODEL = False\n","LOAD_MODEL_FILE = 'YOLOv1.pth'"],"metadata":{"id":"X822xGpC45TF","executionInfo":{"status":"ok","timestamp":1753983279322,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["CLASS_NAMES = ['aeroplane',\n","               'bicycle',\n","               'bird',\n","               'boat',\n","               'bottle',\n","               'bus',\n","               'car',\n","               'cat',\n","               'chair',\n","               'cow',\n","               'diningtable',\n","               'dog',\n","               'horse',\n","               'motorbike',\n","               'person',\n","               'pottedplant',\n","               'sheep',\n","               'sofa',\n","               'train',\n","               'tvmonitor']"],"metadata":{"id":"ivT0sWeytgIW","executionInfo":{"status":"ok","timestamp":1753983279323,"user_tz":360,"elapsed":0,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(seed)"],"metadata":{"id":"Xgz-eRu1lWmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title ###Training Function\n","def train_fn(train_loader, model, optimizer, loss_fn):\n","  model.train()\n","\n","  mean_loss = []\n","\n","  for batch, (X, y) in enumerate(train_loader):\n","    X, y = X.to(device), y.to(device)\n","\n","    y_pred = model(X)\n","\n","    loss = loss_fn(y_pred, y)\n","    mean_loss.append(loss.item())\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  return sum(mean_loss) / len(mean_loss)"],"metadata":{"id":"iZjcMGfhfxUb","executionInfo":{"status":"ok","timestamp":1753983279329,"user_tz":360,"elapsed":0,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["model = YOLOv1(split_size=7, num_boxes=2, num_classes=20).to(device)"],"metadata":{"id":"GIVng5vSjmRf","executionInfo":{"status":"ok","timestamp":1753983279330,"user_tz":360,"elapsed":0,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["if LOAD_MODEL:\n","  load_checkpoint(torch.load(LOAD_MODEL_FILE), model. optimizer)"],"metadata":{"id":"MsM7CryNlH6h","executionInfo":{"status":"ok","timestamp":1753983279331,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY) #THE ORIGINAL PAPER USED SGD (YOU CAN CHANGE IT)\n","loss_fn = YOLO_Loss()\n","\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.2) #THE ORIGINAL PAPER USED MultiStepLR (YOU CAN CHANGE IT)"],"metadata":{"id":"3bmDjEV0ktNc","executionInfo":{"status":"ok","timestamp":1753983279531,"user_tz":360,"elapsed":201,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# @title Training Loop\n","for epoch in tqdm(range(EPOCHS)):\n","\n","  pred_boxes, target_boxes = get_bboxes(\n","      train_dl, model, iou_threshold=0.5, threshold=0.4\n","  )\n","\n","  mAP = mean_average_precision(\n","      pred_boxes, target_boxes, iou_threshold=0.5\n","  )\n","  if SAVE_MODEL:\n","    if mAP >= 0.6:\n","      checkpoint = {\n","          'MODEL_state_dict': model.state_dict(),\n","          'OPTIMIZER_state_dict': optimizer.state_dict()\n","      }\n","      save_checkpoint(checkpoint, filename=LOAD_MODEL_FILE)\n","      print(f\"\\n⚠️ Early stopping: mAP reached {mAP:.2f} at epoch {epoch+1} ⚠️\")\n","\n","      break\n","\n","\n","  ###########################\n","\n","  mean_loss = train_fn(train_dl, model, optimizer, loss_fn)\n","\n","  lr_scheduler.step()\n","\n","  print(f'=================\\nEpoch: {epoch + 1}\\n=================')\n","  print(f'Train mAP: {mAP:.2f}')\n","  print(f'Mean Loss is: {mean_loss:.4f}\\n')"],"metadata":{"id":"cZI2pTTAlrpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if SAVE_MODEL:\n","  torch.save({\n","          'MODEL_state_dict': model.state_dict(),\n","          'OPTIMIZER_state_dict': optimizer.state_dict()\n","          }, 'YOLO_V1_state_dict.pth')"],"metadata":{"id":"XzhqZY3N20UZ","executionInfo":{"status":"aborted","timestamp":1753983314686,"user_tz":360,"elapsed":1,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","\n","for num_train_dl, (X, y) in enumerate(train_dl):\n","    X = X.to(device)\n","    if num_train_dl % SHOW_TRAIN_BATCH_PICS == 0:\n","      for idx in range(X.size(0)):\n","        idx = int(random.uniform(0, BATCH_SIZE))\n","        bboxes = cellboxes_to_boxes(model(X))\n","        bboxes = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n","        plot_image(X[idx].permute(1,2,0).to(\"cpu\"),\n","                    bboxes,\n","                    class_names = CLASS_NAMES)\n","        break"],"metadata":{"id":"2VB3oDtpSDVd","executionInfo":{"status":"aborted","timestamp":1753983314711,"user_tz":360,"elapsed":221870,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Test"],"metadata":{"id":"X56440s1rtBp"}},{"cell_type":"code","source":["# @title ###Testing Function\n","def test_fn(test_loader, model, loss_fn):\n","  model.eval()\n","  total_loss = 0.0\n","  n_batches  = 0\n","\n","  with torch.no_grad():\n","      for X, y in test_loader:\n","          X, y = X.to(device), y.to(device)\n","          preds = model(X)\n","          total_loss += loss_fn(preds, y).item()\n","          n_batches += 1\n","\n","  return total_loss / n_batches"],"metadata":{"id":"F0LDG23Fr-a9","executionInfo":{"status":"aborted","timestamp":1753983314712,"user_tz":360,"elapsed":221870,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Test Loop\n","\n","pred_boxes, target_boxes = get_bboxes(\n","    test_dl, model, iou_threshold=0.5, threshold=0.4\n",")\n","\n","mean_loss = test_fn(test_dl, model, loss_fn)\n","\n","mAP = mean_average_precision(\n","    pred_boxes, target_boxes, iou_threshold=0.5\n",")\n","\n","print(f'Test mAP: {mAP:.2f}')\n","print(f'Mean Loss is: {mean_loss:.4f}\\n')"],"metadata":{"id":"98FgawODSsGN","executionInfo":{"status":"aborted","timestamp":1753983314715,"user_tz":360,"elapsed":221873,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","\n","for num_test_dl, (X, y) in enumerate(test_dl):\n","    X = X.to(device)\n","    if num_test_dl % SHOW_TEST_BATCH_PICS == 0:\n","      for idx in range(X.size(0)):\n","        idx = int(random.uniform(0, BATCH_SIZE))\n","        bboxes = cellboxes_to_boxes(model(X))\n","        bboxes = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.6, box_format=\"midpoint\")\n","        plot_image(X[idx].permute(1,2,0).to(\"cpu\"),\n","                    bboxes,\n","                    class_names = CLASS_NAMES)\n","        break"],"metadata":{"id":"9soG-saDt3lz","executionInfo":{"status":"aborted","timestamp":1753983314716,"user_tz":360,"elapsed":221874,"user":{"displayName":"FP","userId":"09739218640475207253"}}},"execution_count":null,"outputs":[]}]}